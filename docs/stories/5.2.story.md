# Story 5.2: Message Categorization (Edge-Powered)

## Status

Approved

## Story

**As a** creator,
**I want** incoming messages automatically categorized,
**so that** I can quickly identify business opportunities and urgent messages.

## Acceptance Criteria

1. Edge Function deployed for ultra-fast categorization (<500ms)
2. Categories: Fan/Business/Spam/Urgent applied to new messages
3. Fast model selection (GPT-4-Turbo or equivalent)
4. Category badges display in conversation list
5. Filter UI for viewing by category
6. Batch categorization for existing messages
7. 85%+ accuracy achieved in testing

**Acceptance Criteria Notes:**

- **AC 3 Model Selection Clarification**: While the epic mentions "GPT-4-Turbo or equivalent", this story implements Claude 3 Haiku per the architecture's AI Provider Selection Strategy which designates Claude Haiku as the speed-priority model for "Real-time categorization". This satisfies the "or equivalent" clause and is the correct implementation choice for <500ms latency requirements.

**Integration Verification:**

- IV1: Messages still deliver in real-time without categorization delays
- IV2: Firestore listeners continue working with new metadata fields
- IV3: UI remains responsive with category filters active

## Dev Notes

### Previous Story Insights

**Key Learnings from Story 5.1 (AI Infrastructure Foundation):**

Story 5.1 established the foundational AI infrastructure that Story 5.2 will build upon:
- AI provider abstraction layer using Vercel AI SDK
- Model selection logic (fast/quality/cost priority)
- Error handling with retry logic and fallback mechanisms
- Monitoring and logging infrastructure (Langfuse)
- Rate limiting service (Upstash Redis)
- Environment variable configuration for AI services

**IMPORTANT:** Since Story 5.1 is currently "Approved" (not "Done"), assume the infrastructure code from Story 5.1 exists and is ready to use. This story focuses on implementing the first AI feature (message categorization) on top of that infrastructure.

**Project Structure Note from Story 5.1:** The functions directory is at the root level (`functions/`), NOT `firebase/functions/` as shown in some architecture docs.

### Architecture Overview

**Story Type:** Full-Stack (Edge Functions + Backend + Frontend UI)

This story implements the first user-facing AI feature: automatic message categorization. Messages are categorized into four categories:
- **Fan**: General fan engagement, compliments, casual conversation
- **Business**: Sponsorship inquiries, collaboration requests, partnership opportunities
- **Spam**: Promotional content, suspicious links, irrelevant messages
- **Urgent**: Negative sentiment, crisis situations, time-sensitive requests

The categorization happens via Vercel Edge Functions (for <500ms latency) and runs asynchronously without blocking message delivery.

### Edge Functions Architecture

**Technology Stack:** [Source: architecture/tech-stack.md#Phase-2-AI-Intelligence-Layer-Tech-Stack]

- **Edge Functions**: Vercel Edge Functions (latest) - Global edge network with <100ms cold starts
- **AI SDK**: Vercel AI SDK (latest) - Unified AI provider interface
- **Primary Model**: Claude 3 Haiku (Anthropic) - Speed priority for categorization [Source: architecture/tech-stack.md#AI-Provider-Selection-Strategy]
- **Deployment**: Vercel platform with environment variables for API keys

**Why Edge Functions for Categorization:**
- <500ms latency requirement (AC 1)
- Global edge network reduces round-trip time
- Stateless execution perfect for categorization tasks
- Auto-scaling handles traffic spikes

**Edge Function Implementation Pattern:**

```typescript
// vercel/edge-functions/categorize-message.ts
import { createAnthropic } from '@ai-sdk/anthropic';
import { generateText } from 'ai';

export const config = {
  runtime: 'edge', // Vercel Edge Runtime
};

export default async function handler(req: Request) {
  // 1. Extract message data from request
  // 2. Use model selector to get Claude Haiku (speed priority)
  // 3. Call AI provider for categorization
  // 4. Return category with confidence score
  // 5. Handle errors with fallback logic
}
```

### File Locations and Project Structure

**Edge Functions Directory:** [Source: architecture/tech-stack.md, Story 5.1 Task 22]

```
vercel/                         # NEW: Vercel Edge Functions (root-level directory)
├── edge-functions/
│   ├── categorize-message.ts  # NEW: Message categorization endpoint
│   └── utils/
│       ├── aiClient.ts        # NEW: Edge-compatible AI client wrapper
│       └── rateLimiter.ts     # NEW: Edge-compatible rate limiting
├── api/                       # Vercel serverless functions (if needed)
└── middleware.ts              # NEW: Auth middleware for edge functions
```

**Client-Side Service Layer:**

```
services/
├── aiClientService.ts         # NEW: Client-side AI operations
├── categorizationService.ts   # NEW: Categorization-specific operations
└── [existing services]
```

**Frontend Components:**

```
components/
├── conversation/
│   ├── ConversationListItem.tsx      # MODIFY: Add category badge
│   ├── CategoryBadge.tsx             # NEW: Display category indicator
│   └── CategoryFilter.tsx            # NEW: Filter conversations by category
└── chat/
    └── MessageItem.tsx               # MODIFY: Show category in message (optional)
```

**Types:**

```
types/
├── models.ts                   # MODIFY: Add AI metadata to Message type
└── ai.ts                      # EXISTING: AI-specific types from Story 5.1
```

### Data Models and Database Schema

**Message Metadata Extension:** [Source: architecture/data-models.md#Phase-2-AI-Intelligence-Layer-Data-Models, architecture/database-schema.md]

The existing Message schema includes a `metadata` object that will be populated by this story:

```typescript
interface Message {
  id: string;
  conversationId: string;
  senderId: string;
  text: string;
  status: 'sending' | 'delivered' | 'read';
  readBy: string[];
  timestamp: firebase.firestore.Timestamp;
  metadata: {
    // NEW: Populated by categorization
    category?: 'fan_engagement' | 'business_opportunity' | 'spam' | 'urgent' | 'general';
    categoryConfidence?: number; // 0-1 confidence score

    // Future fields (not used in this story)
    sentiment?: string;
    aiProcessed?: boolean;
  };
}
```

**No database schema changes required** - The metadata fields already exist and are optional.

**Conversation Extension for Filtering:** [Source: architecture/data-models.md]

**NOTE**: The `categoryStats` field is a NEW addition in this story (Story 5.2), not present in the baseline architecture documents. This field enables efficient category filtering in the conversation list without querying all messages.

To support category filtering in the conversation list, we'll add a summary field to Conversation:

```typescript
interface Conversation {
  // ... existing fields ...
  categoryStats?: {
    lastCategory?: string;              // Category of most recent message
    categoryCounts?: Record<string, number>; // Count by category
    hasUrgent?: boolean;                // Quick flag for urgent messages
  };
}
```

### Categorization Logic and Prompt Engineering

**Categorization Prompt Strategy:**

The Edge Function will use a carefully crafted prompt for Claude Haiku:

```typescript
const CATEGORIZATION_PROMPT = `You are a message categorization system for a creator messaging platform.

Analyze the following message and categorize it into ONE of these categories:

1. **fan_engagement**: General fan messages, compliments, casual conversation, appreciation
2. **business_opportunity**: Sponsorship inquiries, collaboration requests, partnership proposals, business deals
3. **spam**: Promotional content, suspicious links, irrelevant messages, scams
4. **urgent**: Negative sentiment, crisis situations, complaints, time-sensitive requests

Message to categorize: "{messageText}"

Respond ONLY with valid JSON in this format:
{
  "category": "fan_engagement" | "business_opportunity" | "spam" | "urgent",
  "confidence": 0.95,
  "reasoning": "Brief explanation"
}`;
```

**Category Classification Rules:**
- Default to "general" if confidence < 0.7
- "urgent" takes precedence if negative sentiment detected
- "spam" if suspicious patterns (links, promotional language)
- "business_opportunity" if money/partnership keywords present
- "fan_engagement" for positive, casual messages

**Accuracy Target:** 85%+ (AC 7) - Will be measured in integration tests with labeled dataset

### Edge Function API Specification

**Endpoint:** `POST /api/categorize-message`

**Request:**
```typescript
{
  messageId: string;
  messageText: string;
  conversationId: string;
  senderId: string;
}
```

**Response:**
```typescript
{
  success: boolean;
  category: 'fan_engagement' | 'business_opportunity' | 'spam' | 'urgent' | 'general';
  confidence: number; // 0-1
  latency: number;     // Milliseconds
  model: string;       // 'claude-3-haiku-20240307'
  error?: string;
}
```

**Error Handling:**
- 400: Invalid request (missing fields)
- 401: Unauthorized (invalid auth token)
- 429: Rate limit exceeded
- 500: AI provider error (with fallback logic)
- 503: Service unavailable (circuit breaker open)

### Client-Side Service Layer

**AI Client Service:** [Source: architecture/backend-architecture.md#Service-Layer-Organization, architecture/coding-standards.md#Critical-Fullstack-Rules]

```typescript
// services/aiClientService.ts
import { Config } from '@/constants/Config';

/**
 * Client-side AI operations service
 * Handles communication with Vercel Edge Functions for AI features
 */
export class AIClientService {
  private baseURL: string;

  constructor() {
    this.baseURL = Config.ai.vercelEdgeUrl;
  }

  /**
   * Categorize a message using Edge Function
   * @param messageId - Message ID to categorize
   * @param messageText - Message text content
   * @param conversationId - Parent conversation ID
   * @param senderId - User ID who sent message
   * @returns Categorization result with category and confidence
   * @throws {Error} Network errors, rate limit errors, or AI service errors
   */
  async categorizeMessage(
    messageId: string,
    messageText: string,
    conversationId: string,
    senderId: string
  ): Promise<CategorizationResult> {
    // Implementation calls Edge Function endpoint
    // Returns category, confidence, latency
  }
}
```

**Categorization Service:** [Source: architecture/backend-architecture.md#Service-Layer-Organization]

```typescript
// services/categorizationService.ts
import { updateDoc, doc } from 'firebase/firestore';
import { db } from './firebase';
import { aiClientService } from './aiClientService';

/**
 * Service for message categorization operations
 * Handles automatic categorization and batch processing
 */
export class CategorizationService {
  /**
   * Automatically categorize a new message
   * Runs asynchronously without blocking message delivery
   */
  async categorizeNewMessage(message: Message): Promise<void> {
    try {
      // Call Edge Function for categorization
      const result = await aiClientService.categorizeMessage(
        message.id,
        message.text,
        message.conversationId,
        message.senderId
      );

      // Update message metadata in Firestore
      await this.updateMessageCategory(message.id, message.conversationId, result);

      // Update conversation category stats
      await this.updateConversationCategoryStats(message.conversationId, result.category);
    } catch (error) {
      // Log error but don't throw - categorization failure shouldn't break messaging
      console.error('Categorization failed:', error);
    }
  }

  /**
   * Batch categorize existing messages
   * Used for backfilling categories for historical messages
   */
  async batchCategorizeMessages(conversationId: string, limit: number = 100): Promise<BatchResult> {
    // Implementation for AC 6
  }
}
```

### Frontend UI Components

**Category Badge Component:** [Source: architecture/components.md, architecture/coding-standards.md#TypeScript-Documentation-Standards]

```typescript
// components/conversation/CategoryBadge.tsx
import { View, Text, StyleSheet } from 'react-native';

/**
 * Displays a visual badge indicating message category
 * Shows color-coded indicator with optional label
 *
 * @component
 * @example
 * ```tsx
 * <CategoryBadge category="business_opportunity" size="small" showLabel={false} />
 * ```
 */
interface CategoryBadgeProps {
  /** The message category to display */
  category: 'fan_engagement' | 'business_opportunity' | 'spam' | 'urgent' | 'general';

  /** Badge size variant */
  size?: 'small' | 'medium' | 'large';

  /** Whether to show category label text */
  showLabel?: boolean;
}

export const CategoryBadge: FC<CategoryBadgeProps> = ({ ... }) => {
  // Color mapping:
  // - fan_engagement: Blue (#4A90E2)
  // - business_opportunity: Green (#7ED321)
  // - spam: Red (#D0021B)
  // - urgent: Orange (#F5A623)
  // - general: Gray (#9B9B9B)
};
```

**Category Filter Component:** [Source: architecture/components.md]

```typescript
// components/conversation/CategoryFilter.tsx
import { View, ScrollView, TouchableOpacity, Text } from 'react-native';

/**
 * Horizontal filter bar for selecting conversation categories
 * Allows filtering conversation list by message category
 *
 * @component
 * @example
 * ```tsx
 * <CategoryFilter
 *   selectedCategory={selectedFilter}
 *   onSelectCategory={handleFilterChange}
 *   categoryCounts={{ urgent: 5, business_opportunity: 12 }}
 * />
 * ```
 */
interface CategoryFilterProps {
  /** Currently selected category filter (null = show all) */
  selectedCategory: string | null;

  /** Callback when category filter changes */
  onSelectCategory: (category: string | null) => void;

  /** Count of conversations per category */
  categoryCounts?: Record<string, number>;
}

export const CategoryFilter: FC<CategoryFilterProps> = ({ ... }) => {
  // Horizontal ScrollView with filter chips
  // "All", "Urgent", "Business", "Fan", "Spam"
  // Shows count badges if provided
};
```

**Modified ConversationListItem:** [Source: architecture/components.md]

```typescript
// components/conversation/ConversationListItem.tsx - MODIFICATIONS

// Add category badge to the right side of list item
// Display urgent indicator if hasUrgent flag is true
// Apply subtle background color for urgent conversations
```

### Integration with Message Delivery Flow

**Asynchronous Categorization Pattern:** [Source: Epic 5 Integration Verification IV1]

To ensure messages deliver in real-time without categorization delays:

1. **Message Send Flow:**
   ```
   User sends message → messageService.sendMessage()
   → Message written to Firestore (status: 'sending')
   → Message appears in chat immediately
   → ASYNC: categorizationService.categorizeNewMessage()
   → Message metadata updated with category (background)
   ```

2. **Firestore Trigger (Optional Enhancement):**
   ```
   Cloud Function listens for new messages
   → Calls Edge Function for categorization
   → Updates message metadata
   ```

3. **Client-Side Trigger (Primary Implementation):**
   ```
   After successful message send
   → Call categorizationService in background
   → Fire-and-forget pattern (no await)
   → Update UI when categorization completes
   ```

**CRITICAL:** Categorization must NOT block message delivery. Use fire-and-forget pattern or Firestore trigger.

### Batch Categorization Implementation

**Use Case:** Categorize existing messages in a conversation (AC 6)

**Implementation Strategy:**

```typescript
// services/categorizationService.ts

/**
 * Batch categorize existing messages in a conversation
 * Processes messages in chunks to avoid overwhelming Edge Function
 *
 * @param conversationId - Conversation to process
 * @param limit - Maximum number of messages to categorize (default: 100)
 * @returns Batch processing result with success/failure counts
 */
async batchCategorizeMessages(
  conversationId: string,
  limit: number = 100
): Promise<BatchCategorizationResult> {
  // 1. Fetch uncategorized messages (where metadata.category is missing)
  // 2. Process in batches of 10 to respect rate limits
  // 3. Delay between batches (1s) to avoid rate limit
  // 4. Update message metadata for each successful categorization
  // 5. Track success/failure counts
  // 6. Return summary result
}
```

**UI Trigger:** Add "Categorize Messages" button in conversation settings (future story - not required for this story)

### Environment Variables

**Client-Side Variables:** [Source: Story 5.1 Task 3-4, architecture/coding-standards.md#Environment-Variables]

Already defined in Story 5.1, but verify these are set:

```bash
# Vercel Edge Functions
EXPO_PUBLIC_VERCEL_EDGE_URL=https://your-project.vercel.app/api

# AI Feature Flags
EXPO_PUBLIC_AI_ENABLED=true  # Must be enabled for categorization

# OpenAI/Anthropic API Keys (from Story 5.1)
EXPO_PUBLIC_ANTHROPIC_API_KEY=your_anthropic_api_key_here
```

**Server-Side Variables (Vercel Dashboard):**

These must be configured in Vercel Dashboard for Edge Functions:
- `ANTHROPIC_API_KEY` (server-side, not exposed to client)
- `LANGFUSE_PUBLIC_KEY` (monitoring)
- `LANGFUSE_SECRET_KEY` (monitoring)
- `UPSTASH_REDIS_REST_URL` (rate limiting)
- `UPSTASH_REDIS_REST_TOKEN` (rate limiting)

### Monitoring and Logging

**Metrics to Track:** [Source: architecture/tech-stack.md#AI-Monitoring]

Using Langfuse (configured in Story 5.1):
- Categorization requests per minute
- Edge Function latency (should be <500ms)
- Category distribution (% in each category)
- Categorization accuracy (based on user feedback - future story)
- Error rate by error type
- Token usage and cost per categorization

**Firebase Analytics Events:**

```typescript
// Log categorization events for analytics
logEvent(analytics, 'message_categorized', {
  category: result.category,
  confidence: result.confidence,
  latency: result.latency,
  model: result.model,
});
```

### Error Handling and Fallback

**Error Scenarios:** [Source: architecture/backend-architecture.md#Resilience-Patterns, Story 5.1 Dev Notes]

1. **Edge Function Timeout (>500ms):**
   - Retry with exponential backoff (3 retries max)
   - Fallback to "general" category if all retries fail

2. **AI Provider Error:**
   - Fallback from Claude Haiku to OpenAI GPT-3.5 (if available)
   - Log error for monitoring

3. **Rate Limit Exceeded:**
   - Queue for retry after cooldown period
   - Show user message "Categorization pending"

4. **Network Error:**
   - Retry with exponential backoff
   - Message still delivers - categorization happens when connection restored

5. **Invalid Response:**
   - Default to "general" category
   - Log error for debugging

**Error Handling Pattern:**

```typescript
try {
  const result = await aiClientService.categorizeMessage(...);
  await updateMessageCategory(messageId, result);
} catch (error) {
  if (error.type === 'rate_limit') {
    // Queue for retry
    await retryQueueService.enqueueRetry({...});
  } else if (error.type === 'timeout') {
    // Retry immediately once
    const retryResult = await aiClientService.categorizeMessage(...);
  } else {
    // Fallback to "general" category
    await updateMessageCategory(messageId, { category: 'general', confidence: 0 });
  }

  // Log error for monitoring
  console.error('Categorization failed:', error);
}
```

### Performance Targets

**Latency Requirements:** [Source: AC 1, Epic 5 Integration Verification IV1, IV3]

- Edge Function response: <500ms (p95)
- Message delivery: <100ms (unchanged from Story 4.x)
- Categorization happens asynchronously - no blocking
- UI remains responsive during categorization (IV3)

**Optimization Strategies:**
- Use Claude Haiku (fastest model) for categorization
- Edge Functions deployed globally (low latency)
- Rate limiting prevents overload
- Batch processing for backfilling (10 messages/batch)

### Testing Requirements

**Test File Locations:** [Source: architecture/testing-strategy.md#Test-Organization]

```
tests/
├── unit/
│   ├── services/
│   │   ├── aiClientService.test.ts           # NEW: Edge Function client tests
│   │   └── categorizationService.test.ts     # NEW: Categorization logic tests
│   └── components/
│       ├── CategoryBadge.test.tsx            # NEW: Badge component tests
│       └── CategoryFilter.test.tsx           # NEW: Filter component tests
├── integration/
│   ├── categorization-edge-function.test.ts  # NEW: Edge Function integration
│   ├── categorization-accuracy.test.ts       # NEW: Accuracy testing with labeled dataset
│   └── categorization-flow.test.ts           # NEW: End-to-end categorization flow
└── e2e/
    └── message-categorization.e2e.ts         # NEW: E2E test for categorization feature
```

**Testing Frameworks:** [Source: architecture/testing-strategy.md, architecture/tech-stack.md]

- **Unit/Integration**: Jest (29.x) + React Native Testing Library
- **E2E**: Detox (latest)
- **Test Execution**: `npm test` for all tests
- **Coverage Target**: 85%+ for service layer, 80%+ for components

**Test Standards:**

1. **Unit Tests - AI Client Service:**
   - Mock HTTP client for Edge Function calls
   - Test successful categorization response parsing
   - Test error handling for all error types (network, timeout, rate_limit, invalid_response)
   - Test retry logic with exponential backoff
   - Verify request format and authentication headers

2. **Unit Tests - Categorization Service:**
   - Mock aiClientService and Firestore
   - Test automatic categorization flow
   - Test batch categorization with pagination
   - Test conversation category stats updates
   - Test error handling and fallback to "general" category

3. **Unit Tests - UI Components:**
   - CategoryBadge: Test rendering for each category, color mapping, size variants
   - CategoryFilter: Test filter selection, count badges, "All" option
   - ConversationListItem: Test category badge display, urgent indicator

4. **Integration Tests - Edge Function:**
   - **Prerequisites**: Deploy Edge Function to Vercel preview environment
   - Real API calls to Edge Function with test messages
   - Verify response format and latency (<500ms)
   - Test with various message types (fan, business, spam, urgent)
   - Verify category assignment matches expectations
   - Test rate limiting behavior
   - Test error responses (invalid input, auth failure)

5. **Integration Tests - Categorization Accuracy (AC 7):**
   - **Labeled Dataset**: Create 100+ test messages with known categories
   - Run categorization on entire dataset
   - Calculate accuracy: (correct predictions / total) * 100
   - Target: 85%+ accuracy
   - Generate confusion matrix for debugging
   - Document edge cases where categorization fails

6. **Integration Tests - Full Flow:**
   - Send message → automatic categorization → metadata update → UI update
   - Test with Firestore Emulator for realistic environment
   - Verify message delivers immediately (not blocked by categorization)
   - Verify real-time listener updates UI with category

7. **E2E Tests - Message Categorization:**
   - Login as user
   - Send message in conversation
   - Verify message appears immediately
   - Wait for categorization to complete
   - Verify category badge appears in conversation list
   - Test category filter functionality
   - Test batch categorization button (if implemented)

**Known Limitation:** [Source: architecture/testing-strategy.md#Known-Test-Infrastructure-Limitations]
- Jest's instanceof checks may fail for AI provider errors
- Test using error.code properties instead
- Integration tests with real APIs provide confidence

### Coding Standards

**TypeScript Documentation:** [Source: architecture/coding-standards.md#TypeScript-Documentation-Standards]

All public APIs must include:
- JSDoc comments with description
- @param tags for all parameters
- @returns tag describing return value
- @throws tag for possible exceptions
- @example with valid TypeScript code
- Property comments for interfaces using `/** */`

**Critical Rules:** [Source: architecture/coding-standards.md#Critical-Fullstack-Rules]

- **Type Sharing**: Define all AI types in `/types` directory
- **No Direct External Access**: Components never call Edge Functions directly - use service layer
- **Environment Variables**: Access through `Config.ai.*`, never `process.env` directly
- **Error Handling**: All async AI operations must have try-catch with user-friendly messages
- **Optimistic Updates**: Not applicable for categorization (runs in background)
- **Race Condition Prevention**: Categorization runs after message delivery, no race conditions expected

### Backward Compatibility

**Integration Verification:** [Source: Epic 5 Integration Verification]

- **IV1**: Messages still deliver in real-time without categorization delays
  - Implementation: Categorization runs asynchronously via fire-and-forget pattern
  - Message send flow unchanged from Story 4.x
  - No blocking operations added to message delivery path

- **IV2**: Firestore listeners continue working with new metadata fields
  - Implementation: Metadata is optional field, doesn't break existing listeners
  - Existing code ignores metadata if not present
  - Real-time updates work for both old and new messages

- **IV3**: UI remains responsive with category filters active
  - Implementation: Category filters use existing Firestore query patterns
  - Filtering is client-side on already-loaded data (no new queries)
  - No performance impact on conversation list rendering

### Testing

See detailed testing requirements in "Testing Requirements" section above.

## Tasks / Subtasks

- [ ] **Task 1: Set Up Vercel Edge Function Project Structure** (AC: 1)
  - [ ] Create `vercel/` directory in project root (root-level directory)
  - [ ] Create `vercel/edge-functions/` subdirectory
  - [ ] Create `vercel/edge-functions/utils/` for shared utilities
  - [ ] Create `vercel.json` configuration file
  - [ ] Configure Edge Function routes in vercel.json
  - [ ] Source: [architecture/tech-stack.md#Edge-Functions, Story 5.1 Task 22]

- [ ] **Task 2: Install Edge Function Dependencies** (AC: 1)
  - [ ] Initialize package.json in `vercel/` directory
  - [ ] Install `ai@latest` and `@ai-sdk/anthropic@latest`
  - [ ] Install `@upstash/redis@latest` for rate limiting
  - [ ] Install `@vercel/edge@latest` for edge runtime types
  - [ ] Verify all dependencies compatible with Edge Runtime
  - [ ] Source: [architecture/tech-stack.md#AI-SDK, #Rate-Limiting]

- [ ] **Task 3: Implement Edge-Compatible AI Client** (AC: 1, 3)
  - [ ] Create `vercel/edge-functions/utils/aiClient.ts`
  - [ ] Initialize Anthropic provider using Vercel AI SDK
  - [ ] Implement `categorizeMessage()` function with Claude Haiku
  - [ ] Add categorization prompt engineering (fan/business/spam/urgent)
  - [ ] Parse AI response and validate JSON format
  - [ ] Add error handling with retry logic (3 retries, exponential backoff)
  - [ ] Add JSDoc documentation
  - [ ] Source: [architecture/tech-stack.md#Secondary-LLM, Story 5.1 Dev Notes]

- [ ] **Task 4: Implement Edge Function Rate Limiter** (AC: 1)
  - [ ] Create `vercel/edge-functions/utils/rateLimiter.ts`
  - [ ] Initialize Upstash Redis client for Edge Runtime
  - [ ] Implement sliding window rate limiting (100 requests/hour per user)
  - [ ] Return 429 error if rate limit exceeded
  - [ ] Add JSDoc documentation
  - [ ] Source: [Story 5.1 Task 13, architecture/tech-stack.md#Rate-Limiting]

- [ ] **Task 5: Create Categorize Message Edge Function** (AC: 1, 2, 3)
  - [ ] Create `vercel/edge-functions/categorize-message.ts`
  - [ ] Set Edge Runtime config: `export const config = { runtime: 'edge' }`
  - [ ] Validate request body (messageId, messageText, conversationId, senderId)
  - [ ] Implement authentication check (verify auth token)
  - [ ] Check rate limit for user
  - [ ] Call aiClient.categorizeMessage() with message text
  - [ ] Apply categorization rules (fan/business/spam/urgent)
  - [ ] Return JSON response with category, confidence, latency, model
  - [ ] Handle errors and return appropriate HTTP status codes
  - [ ] Add request/response logging for monitoring
  - [ ] Source: [architecture/backend-architecture.md#Service-Architecture]

- [ ] **Task 6: Deploy Edge Function to Vercel** (AC: 1)
  - [ ] **Vercel Project Setup (if not already configured):**
    - [ ] Install Vercel CLI globally: `npm install -g vercel`
    - [ ] Run `vercel login` to authenticate
    - [ ] Run `vercel link` in project root to link to Vercel project (create new if needed)
    - [ ] Confirm project settings (framework preset: Other, build command: none, output directory: vercel)
  - [ ] Set environment variables in Vercel Dashboard:
    - [ ] Navigate to Project Settings → Environment Variables
    - [ ] Add: ANTHROPIC_API_KEY (server-side, Production + Preview environments)
    - [ ] Add: UPSTASH_REDIS_REST_URL (Production + Preview)
    - [ ] Add: UPSTASH_REDIS_REST_TOKEN (Production + Preview)
    - [ ] Add: LANGFUSE_PUBLIC_KEY (Production + Preview)
    - [ ] Add: LANGFUSE_SECRET_KEY (Production + Preview)
  - [ ] Deploy to preview environment: `vercel` (without --prod flag)
  - [ ] Verify Edge Function accessible at preview URL + `/api/categorize-message`
  - [ ] Test latency meets <500ms requirement using preview environment
  - [ ] Deploy to production: `vercel --prod`
  - [ ] Update EXPO_PUBLIC_VERCEL_EDGE_URL in .env with production URL
  - [ ] Document deployment process in vercel/edge-functions/README.md
  - [ ] Source: [architecture/tech-stack.md#Edge-Functions]

- [ ] **Task 7: Extend Message Type with AI Metadata** (AC: 2)
  - [ ] Open `types/models.ts`
  - [ ] Modify Message interface to include metadata.category and metadata.categoryConfidence
  - [ ] Add type union for category: 'fan_engagement' | 'business_opportunity' | 'spam' | 'urgent' | 'general'
  - [ ] Add JSDoc comments explaining new fields
  - [ ] Source: [architecture/data-models.md#Phase-2-AI-Intelligence-Layer-Data-Models]

- [ ] **Task 8: Extend Conversation Type with Category Stats** (AC: 5)
  - [ ] Open `types/models.ts`
  - [ ] Add optional `categoryStats` field to Conversation interface (NEW field added in Story 5.2)
  - [ ] Define CategoryStats interface (lastCategory, categoryCounts, hasUrgent)
  - [ ] Add JSDoc comments noting this is a new field for AI categorization
  - [ ] Source: [architecture/data-models.md]

- [ ] **Task 9: Implement AI Client Service** (AC: 1)
  - [ ] Create `services/aiClientService.ts`
  - [ ] Implement AIClientService class
  - [ ] Add `categorizeMessage()` method that calls Edge Function
  - [ ] Use Config.ai.vercelEdgeUrl for base URL
  - [ ] Add authentication headers (Firebase Auth token)
  - [ ] Parse Edge Function response
  - [ ] Implement error handling with retry logic
  - [ ] Add JSDoc documentation with @param, @returns, @throws, @example
  - [ ] Export singleton instance
  - [ ] Source: [architecture/backend-architecture.md#Service-Layer-Organization]

- [ ] **Task 10: Implement Categorization Service** (AC: 2, 6)
  - [ ] Create `services/categorizationService.ts`
  - [ ] Implement CategorizationService class
  - [ ] Add `categorizeNewMessage()` method for automatic categorization
  - [ ] Add `updateMessageCategory()` helper to update Firestore message metadata
  - [ ] Add `updateConversationCategoryStats()` helper to update conversation stats
  - [ ] Add `batchCategorizeMessages()` method for backfilling (AC 6)
  - [ ] Implement batch processing with rate limit delays (10 messages/batch, 1s delay)
  - [ ] Add error handling with fallback to "general" category
  - [ ] Add JSDoc documentation
  - [ ] Export singleton instance
  - [ ] Source: [architecture/backend-architecture.md#Service-Layer-Organization]

- [ ] **Task 11: Integrate Categorization into Message Send Flow** (AC: 2, IV1)
  - [ ] Open `services/messageService.ts`
  - [ ] Import categorizationService
  - [ ] After successful message send, call categorizationService.categorizeNewMessage() in background
  - [ ] Use fire-and-forget pattern (no await) to avoid blocking message delivery
  - [ ] Wrap categorization call in try-catch to prevent errors from affecting messaging
  - [ ] Add logging for categorization failures
  - [ ] Source: [architecture/backend-architecture.md#Optimistic-UI-Updates]

- [ ] **Task 12: Create Category Badge Component** (AC: 4)
  - [ ] Create `components/conversation/CategoryBadge.tsx`
  - [ ] Define CategoryBadgeProps interface (category, size, showLabel)
  - [ ] Implement component with color mapping:
    - fan_engagement: Blue (#4A90E2)
    - business_opportunity: Green (#7ED321)
    - spam: Red (#D0021B)
    - urgent: Orange (#F5A623)
    - general: Gray (#9B9B9B)
  - [ ] Support size variants (small, medium, large)
  - [ ] Add optional label text
  - [ ] Use React.memo for performance
  - [ ] Add JSDoc documentation with @component, @example
  - [ ] Create test file with snapshot tests
  - [ ] Source: [architecture/components.md, architecture/frontend-architecture.md#Component-Template]

- [ ] **Task 13: Create Category Filter Component** (AC: 5)
  - [ ] Create `components/conversation/CategoryFilter.tsx`
  - [ ] Define CategoryFilterProps interface (selectedCategory, onSelectCategory, categoryCounts)
  - [ ] Implement horizontal ScrollView with filter chips
  - [ ] Add "All" filter option (clears filter)
  - [ ] Display category icons and labels
  - [ ] Show count badges for each category (if provided)
  - [ ] Highlight selected filter
  - [ ] Use React.memo for performance
  - [ ] Add JSDoc documentation
  - [ ] Create test file
  - [ ] Source: [architecture/components.md, architecture/frontend-architecture.md]

- [ ] **Task 14: Modify ConversationListItem Component** (AC: 4)
  - [ ] Open `components/conversation/ConversationListItem.tsx`
  - [ ] Import CategoryBadge component
  - [ ] Add category badge to the right side of list item
  - [ ] Display urgent indicator if conversation.categoryStats.hasUrgent is true
  - [ ] Apply subtle background color for urgent conversations (light orange tint)
  - [ ] Ensure layout remains balanced with new badge
  - [ ] Test rendering with various categories
  - [ ] Source: [architecture/components.md]

- [ ] **Task 15: Add Category Filter to Conversation List Screen** (AC: 5)
  - [ ] Open `app/(tabs)/conversations/index.tsx`
  - [ ] Import CategoryFilter component
  - [ ] Add state for selected filter: `const [selectedCategory, setSelectedCategory] = useState<string | null>(null)`
  - [ ] Calculate category counts from conversations array
  - [ ] Add CategoryFilter component above conversation list
  - [ ] Filter conversations based on selectedCategory (use conversation.categoryStats.lastCategory)
  - [ ] Ensure real-time updates work with filter active (IV2)
  - [ ] Test UI responsiveness with filter (IV3)
  - [ ] Source: [architecture/frontend-architecture.md#State-Management-Patterns]

- [ ] **Task 16: Update Conversation Service for Category Stats** (AC: 4, 5)
  - [ ] Open `services/conversationService.ts`
  - [ ] Add method `updateCategoryStats(conversationId, category)` to update conversation.categoryStats
  - [ ] Increment category count in categoryCounts map
  - [ ] Set lastCategory to most recent category
  - [ ] Set hasUrgent flag if category is 'urgent'
  - [ ] Add error handling
  - [ ] Call this method from categorizationService after categorization
  - [ ] Source: [architecture/backend-architecture.md#Service-Layer-Organization]

- [ ] **Task 17: Add Monitoring for Categorization Operations** (AC: 1, 7)
  - [ ] Open `vercel/edge-functions/categorize-message.ts`
  - [ ] Add Langfuse event logging for categorization operations
  - [ ] Track: operationType: 'categorize_message', category, confidence, latency, model, success/failure
  - [ ] Add Firebase Analytics custom event: 'message_categorized'
  - [ ] Log error types for failed categorizations
  - [ ] Add cost tracking (token usage)
  - [ ] Source: [Story 5.1 Task 12, architecture/tech-stack.md#AI-Monitoring]

- [ ] **Task 18: Write Unit Tests for AI Client Service** (AC: 1)
  - [ ] Create `tests/unit/services/aiClientService.test.ts`
  - [ ] Mock fetch for HTTP requests
  - [ ] Test successful categorization request and response parsing
  - [ ] Test authentication header inclusion
  - [ ] Test error handling for network errors, timeout errors, rate limit errors
  - [ ] Test retry logic with exponential backoff
  - [ ] Test invalid response format handling
  - [ ] 85%+ coverage target
  - [ ] Source: [architecture/testing-strategy.md#Frontend-Component-Test]

- [ ] **Task 19: Write Unit Tests for Categorization Service** (AC: 2, 6)
  - [ ] Create `tests/unit/services/categorizationService.test.ts`
  - [ ] Mock aiClientService and Firestore
  - [ ] Test automatic categorization flow
  - [ ] Test message metadata update
  - [ ] Test conversation category stats update
  - [ ] Test batch categorization with pagination
  - [ ] Test error handling and fallback to "general" category
  - [ ] Test fire-and-forget pattern (no errors thrown)
  - [ ] 85%+ coverage target
  - [ ] Source: [architecture/testing-strategy.md]

- [ ] **Task 20: Write Unit Tests for UI Components** (AC: 4, 5)
  - [ ] Create `tests/unit/components/CategoryBadge.test.tsx`
  - [ ] Test rendering for each category (fan, business, spam, urgent, general)
  - [ ] Test color mapping correctness
  - [ ] Test size variants (small, medium, large)
  - [ ] Test label display
  - [ ] Create `tests/unit/components/CategoryFilter.test.tsx`
  - [ ] Test filter selection handling
  - [ ] Test count badge display
  - [ ] Test "All" option
  - [ ] Test selected state highlighting
  - [ ] 80%+ coverage target for components
  - [ ] Source: [architecture/testing-strategy.md#Frontend-Component-Test]

- [ ] **Task 21: Create Labeled Dataset for Accuracy Testing** (AC: 7)
  - [ ] Create `tests/integration/data/` directory
  - [ ] Create `tests/integration/data/labeled-messages.json`
  - [ ] Include 100+ messages with ground truth labels
  - [ ] Cover all categories: fan_engagement (25), business_opportunity (25), spam (25), urgent (25)
  - [ ] Include edge cases: ambiguous messages, short messages, emoji-only messages
  - [ ] Ensure dataset is diverse (different lengths, tones, contexts)
  - [ ] Document dataset creation methodology in file header comments
  - [ ] Source: [AC 7, Task 22 prerequisite]

- [ ] **Task 22: Write Integration Tests for Edge Function** (AC: 1, 3)
  - [ ] **Prerequisites**: Deploy Edge Function to Vercel preview environment (Task 6)
  - [ ] Create `tests/integration/categorization-edge-function.test.ts`
  - [ ] Add skip condition: `if (!process.env.EDGE_FUNCTION_URL) { test.skip(...) }`
  - [ ] Test real Edge Function call with sample message
  - [ ] Verify response format (category, confidence, latency, model)
  - [ ] Verify latency <500ms (AC 1)
  - [ ] Test categorization for different message types:
    - "Love your content!" → fan_engagement
    - "Interested in sponsorship deal?" → business_opportunity
    - "Click here for free money!" → spam
    - "Very disappointed with your service!" → urgent
  - [ ] Test rate limiting (send 101 requests rapidly, expect 429 on 101st)
  - [ ] Test authentication (missing token should return 401)
  - [ ] Test invalid request body (missing fields should return 400)
  - [ ] Source: [architecture/testing-strategy.md#Backend-API-Test]

- [ ] **Task 23: Write Integration Tests for Categorization Accuracy** (AC: 7)
  - [ ] **Prerequisites**: Task 21 completed (labeled dataset created)
  - [ ] Create `tests/integration/categorization-accuracy.test.ts`
  - [ ] Load labeled dataset from `tests/integration/data/labeled-messages.json`
  - [ ] Run categorization on entire dataset
  - [ ] Calculate accuracy: (correct predictions / total) * 100
  - [ ] Assert accuracy >= 85% (AC 7)
  - [ ] Generate confusion matrix
  - [ ] Log misclassified examples for debugging
  - [ ] Document edge cases where categorization fails
  - [ ] Source: [AC 7, architecture/testing-strategy.md]

- [ ] **Task 24: Write Integration Tests for Full Categorization Flow** (AC: 2, IV1, IV2)
  - [ ] Create `tests/integration/categorization-flow.test.ts`
  - [ ] Use Firebase Emulator Suite for realistic testing
  - [ ] Send message using messageService
  - [ ] Verify message appears immediately (IV1)
  - [ ] Wait for categorization to complete (poll message metadata)
  - [ ] Verify message metadata updated with category
  - [ ] Verify conversation categoryStats updated
  - [ ] Verify Firestore listener triggers UI update (IV2)
  - [ ] Test error handling when Edge Function unavailable
  - [ ] Test fallback to "general" category on error
  - [ ] Source: [architecture/testing-strategy.md#Backend-API-Test]

- [ ] **Task 25: Write E2E Tests for Message Categorization** (AC: 4, 5)
  - [ ] Create `tests/e2e/message-categorization.e2e.ts`
  - [ ] Login as test user
  - [ ] Navigate to conversation
  - [ ] Send test message
  - [ ] Verify message appears immediately (not blocked by categorization)
  - [ ] Wait for category badge to appear (up to 5s timeout)
  - [ ] Navigate back to conversation list
  - [ ] Verify category badge visible in ConversationListItem
  - [ ] Test category filter:
    - Tap "Urgent" filter
    - Verify only urgent conversations shown
    - Tap "All" to clear filter
    - Verify all conversations shown
  - [ ] Source: [architecture/testing-strategy.md#E2E-Test]

- [ ] **Task 26: Verify Backward Compatibility** (IV1, IV2, IV3)
  - [ ] Run existing test suite: `npm test`
  - [ ] Verify no regressions in message delivery tests
  - [ ] Verify message send/receive latency unchanged (<100ms)
  - [ ] Test message delivery with AI feature flag disabled (Config.ai.aiEnabled = false)
  - [ ] Verify app functions normally without categorization
  - [ ] Test Firestore listeners with mix of categorized and uncategorized messages
  - [ ] Verify conversation list renders smoothly with category filters (60fps)
  - [ ] Test with slow network connection (3G throttling)
  - [ ] Source: [Epic 5 Integration Verification]

- [ ] **Task 27: Performance Testing** (AC: 1, IV3)
  - [ ] Measure Edge Function latency (p50, p95, p99)
  - [ ] Assert p95 latency <500ms (AC 1)
  - [ ] Measure message delivery latency (should remain <100ms)
  - [ ] Test UI responsiveness with category filter active
  - [ ] Measure FlatList scroll performance (should remain 60fps)
  - [ ] Test with 100+ conversations in list
  - [ ] Test batch categorization performance (100 messages)
  - [ ] Source: [AC 1, Epic 5 Integration Verification IV3]

- [ ] **Task 28: Documentation** (AC: All)
  - [ ] Create `vercel/edge-functions/README.md` documenting:
    - Edge Function purpose and architecture
    - Deployment process (including Vercel CLI setup from Task 6)
    - Environment variable setup
    - API endpoint specifications
    - Testing approach
  - [ ] Update main project README with AI categorization feature
  - [ ] Add inline code comments for complex logic
  - [ ] Document categorization prompt engineering decisions
  - [ ] Create user guide for category filter feature
  - [ ] Source: [architecture/coding-standards.md#TypeScript-Documentation-Standards]

## Change Log

| Date       | Version | Description                          | Author        |
| ---------- | ------- | ------------------------------------ | ------------- |
| 2025-10-23 | 1.0     | Initial story draft created          | Bob (SM)      |
| 2025-10-23 | 2.0     | Validation corrections applied (critical task sequencing fix + should-fix improvements) | Sarah (PO) |
| 2025-10-23 | 2.1     | Bug fix: Firebase initialization order in categorizationService (Fix #8) | James (Dev) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

**2025-10-23: Firebase Initialization Order Bug**
- **Issue**: `categorizationService` singleton threw "Firebase not initialized" error during module load
- **Root Cause**: Class property `private db = getFirebaseDb()` executed before `initializeFirebase()` was called
- **Fix**: Changed to lazy getter pattern `private get db(): Firestore { return getFirebaseDb(); }`
- **Documentation**: Added to critical-infrastructure-fixes.md as Fix #8
- **File**: services/categorizationService.ts:40

### Completion Notes

**Implementation Status: PARTIAL (Tasks 1-11 of 28 Complete)**

**CRITICAL UPDATES - 2025-10-23:**

1. **Architecture Deviation - Directory Structure:**
   - **Planned:** `vercel/edge-functions/` directory structure
   - **Implemented:** Standard Vercel `/api/` directory structure
   - **Reason:** Vercel's best practice is to use `/api` for automatic Edge Function discovery
   - **Impact:** All file paths in this story and future stories (5.3, 5.4) updated to reference `/api/`
   - **Status:** ✅ Stories 5.3 and 5.4 updated with correct paths

2. **CRITICAL FIX - AI Model Corrected:**
   - **Originally Implemented:** Claude 3 Haiku (Anthropic) - INCORRECT
   - **Corrected To:** GPT-4o-mini (OpenAI) - per tech-stack.md
   - **Reason:** tech-stack.md Line 51 specifies "OpenAI-only approach"
   - **Impact:** Story 5.3 Task 0 (model migration) is now COMPLETED
   - **Files Changed:**
     - `/api/utils/aiClient.ts` - Changed from `@ai-sdk/anthropic` to `@ai-sdk/openai`
     - `/api/categorize-message.ts` - Updated to use `OPENAI_API_KEY` and `gpt-4o-mini`
     - `/vercel.json` - Removed `ANTHROPIC_API_KEY` reference
     - `/vercel/package.json` - Removed `@ai-sdk/anthropic`, added `@ai-sdk/openai`

**Completed Tasks (1-11):**
1. ✅ Vercel Edge Function project structure (using `/api/` directory)
2. ✅ Edge Function dependencies installed in `vercel/package.json`
3. ✅ Edge-compatible AI Client implemented with Claude Haiku integration
4. ✅ Rate Limiter with Upstash Redis (sliding window algorithm)
5. ✅ Categorize Message Edge Function endpoint with full error handling
6. ⏸️ **DEFERRED** - Edge Function deployment (requires environment variables setup)
7. ✅ Message type extended with category and categoryConfidence fields
8. ✅ Conversation type extended with categoryStats field
9. ✅ AI Client Service with auth token integration and retry logic
10. ✅ Categorization Service with batch processing support
11. ✅ Integration into message send flow (fire-and-forget pattern, non-blocking)

**Remaining Tasks (12-28):**
- Frontend components (CategoryBadge, CategoryFilter, ConversationListItem updates)
- Conversation Service category stats methods
- Monitoring integration (Langfuse)
- Comprehensive test suite (unit, integration, E2E)
- Documentation

**Deployment Prerequisites:**
- Vercel project linked ✅ (completed by user)
- Environment variables needed in Vercel Dashboard:
  - ANTHROPIC_API_KEY
  - UPSTASH_REDIS_REST_URL
  - UPSTASH_REDIS_REST_TOKEN
  - LANGFUSE_PUBLIC_KEY (optional)
  - LANGFUSE_SECRET_KEY (optional)
- Client-side env var: EXPO_PUBLIC_VERCEL_EDGE_URL (set after deployment)

### File List

**New Files Created:**

Backend (Edge Functions):
- `/api/categorize-message.ts` - Main Edge Function endpoint
- `/api/utils/aiClient.ts` - Claude Haiku AI client with retry logic
- `/api/utils/rateLimiter.ts` - Upstash Redis rate limiter

Backend (Services):
- `/services/aiClientService.ts` - Client-side AI operations service
- `/services/categorizationService.ts` - Message categorization orchestration

**Modified Files:**

Type Definitions:
- `/types/models.ts` - Extended Message.metadata with category/categoryConfidence, added Conversation.categoryStats

Configuration:
- `/vercel.json` - Configured Edge Function runtime for `/api/**/*.ts`

Services:
- `/services/messageService.ts` - Integrated background categorization (fire-and-forget)
- `/services/categorizationService.ts` - Fixed Firebase initialization order bug (lazy getter pattern)

**Files to be Created (Remaining Tasks):**
- `/components/conversation/CategoryBadge.tsx`
- `/components/conversation/CategoryFilter.tsx`
- `/tests/unit/services/aiClientService.test.ts`
- `/tests/unit/services/categorizationService.test.ts`
- `/tests/unit/components/CategoryBadge.test.tsx`
- `/tests/unit/components/CategoryFilter.test.tsx`
- `/tests/integration/categorization-edge-function.test.ts`
- `/tests/integration/categorization-accuracy.test.ts`
- `/tests/integration/categorization-flow.test.ts`
- `/tests/integration/data/labeled-messages.json`
- `/tests/e2e/message-categorization.e2e.ts`
- `/api/README.md` (deployment documentation)

## QA Results

_This section will be populated by the QA agent after implementation review._
